\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{none/global//global/global/global}
\HyPL@Entry{0<</S/r>>}
\abx@aux@cite{0}{casal2023ai}
\abx@aux@segm{0}{0}{casal2023ai}
\HyPL@Entry{1<</S/r>>}
\abx@aux@cite{0}{zhai2021review}
\abx@aux@segm{0}{0}{zhai2021review}
\HyPL@Entry{5<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {第一章\hspace  {.3em}}人工智能的基础与历史演进}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{chap:ai_basics}{{一}{1}{人工智能的基础与历史演进}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}引言}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:intro_chap1}{{1.1}{1}{引言}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}核心概念与定义}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:core_concepts}{{1.2}{1}{核心概念与定义}{section.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}人工智能的定义}{1}{subsection.1.2.1}\protected@file@percent }
\newlabel{ssec:ai_definition}{{1.2.1}{1}{人工智能的定义}{subsection.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}强人工智能与弱人工智能}{2}{subsection.1.2.2}\protected@file@percent }
\newlabel{ssec:strong_weak_ai}{{1.2.2}{2}{强人工智能与弱人工智能}{subsection.1.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces 强人工智能与弱人工智能的区别示意图}}{2}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:contray}{{1.1}{2}{强人工智能与弱人工智能的区别示意图}{figure.caption.4}{}}
\abx@aux@cite{0}{mahesh2020machine}
\abx@aux@segm{0}{0}{mahesh2020machine}
\abx@aux@cite{0}{lecun2015deep}
\abx@aux@segm{0}{0}{lecun2015deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}机器学习与深度学习概述}{3}{subsection.1.2.3}\protected@file@percent }
\newlabel{ssec:ml_dl_overview}{{1.2.3}{3}{机器学习与深度学习概述}{subsection.1.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces 机器学习的主要类型示意图}}{3}{figure.caption.5}\protected@file@percent }
\newlabel{fig:rate}{{1.2}{3}{机器学习的主要类型示意图}{figure.caption.5}{}}
\abx@aux@cite{0}{glielmo2021unsupervised}
\abx@aux@segm{0}{0}{glielmo2021unsupervised}
\abx@aux@cite{0}{matsuo2022deep}
\abx@aux@segm{0}{0}{matsuo2022deep}
\abx@aux@cite{0}{ahmed2023deep}
\abx@aux@segm{0}{0}{ahmed2023deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces 机器学习的主要类型示意图}}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:parse}{{1.3}{5}{机器学习的主要类型示意图}{figure.caption.6}{}}
\newlabel{fig:grouped_a}{{1.4a}{6}{人工智能、机器学习与深度学习的关系示意图}{figure.caption.7}{}}
\newlabel{sub@fig:grouped_a}{{a}{6}{人工智能、机器学习与深度学习的关系示意图}{figure.caption.7}{}}
\newlabel{fig:grouped_b}{{1.4b}{6}{一个简单的神经网络结构示意图}{figure.caption.7}{}}
\newlabel{sub@fig:grouped_b}{{b}{6}{一个简单的神经网络结构示意图}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces 人工智能、机器学习与深度学习的层级关系及神经网络结构}}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:grouped_total}{{1.4}{6}{人工智能、机器学习与深度学习的层级关系及神经网络结构}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}哲学思辨与早期探索}{6}{section.1.3}\protected@file@percent }
\newlabel{sec:early_exploration}{{1.3}{6}{哲学思辨与早期探索}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}图灵测试与机器智能的界定}{6}{subsection.1.3.1}\protected@file@percent }
\newlabel{ssec:turing_test}{{1.3.1}{6}{图灵测试与机器智能的界定}{subsection.1.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces 图灵测试示意图}}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:turing_test}{{1.5}{6}{图灵测试示意图}{figure.caption.8}{}}
\abx@aux@cite{0}{jung2023concerning}
\abx@aux@segm{0}{0}{jung2023concerning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}达特茅斯会议与人工智能的诞生}{7}{subsection.1.3.2}\protected@file@percent }
\newlabel{ssec:dartmouth_conference}{{1.3.2}{7}{达特茅斯会议与人工智能的诞生}{subsection.1.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces 达特茅斯会议的主要参与者}}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:dartmouth_conference}{{1.6}{7}{达特茅斯会议的主要参与者}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}早期AI研究范式}{7}{subsection.1.3.3}\protected@file@percent }
\newlabel{ssec:early_paradigms}{{1.3.3}{7}{早期AI研究范式}{subsection.1.3.3}{}}
\abx@aux@cite{0}{maurer2021cognitive}
\abx@aux@segm{0}{0}{maurer2021cognitive}
\abx@aux@cite{0}{shehadeh2024expert}
\abx@aux@segm{0}{0}{shehadeh2024expert}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}AI的发展阶段与“寒冬”}{8}{section.1.4}\protected@file@percent }
\newlabel{sec:ai_stages_winters}{{1.4}{8}{AI的发展阶段与“寒冬”}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}第一次AI寒冬（约1974-1980年）}{8}{subsection.1.4.1}\protected@file@percent }
\newlabel{ssec:first_winter}{{1.4.1}{8}{第一次AI寒冬（约1974-1980年）}{subsection.1.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}第二次AI寒冬（约1987-1993年）}{8}{subsection.1.4.2}\protected@file@percent }
\newlabel{ssec:second_winter}{{1.4.2}{8}{第二次AI寒冬（约1987-1993年）}{subsection.1.4.2}{}}
\abx@aux@cite{0}{xu2022separable}
\abx@aux@segm{0}{0}{xu2022separable}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}AI的复兴与深度学习的爆发}{9}{subsection.1.4.3}\protected@file@percent }
\newlabel{ssec:ai_resurgence}{{1.4.3}{9}{AI的复兴与深度学习的爆发}{subsection.1.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}总结}{9}{section.1.5}\protected@file@percent }
\newlabel{sec:conclusion_chap1}{{1.5}{9}{总结}{section.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces 人工智能发展历程的关键节点与范式演进}}{10}{figure.caption.10}\protected@file@percent }
\newlabel{fig:ai_history}{{1.7}{10}{人工智能发展历程的关键节点与范式演进}{figure.caption.10}{}}
\newlabel{fig:model_params_growth}{{1.8a}{10}{模型参数量随时间增长情况}{figure.caption.11}{}}
\newlabel{sub@fig:model_params_growth}{{a}{10}{模型参数量随时间增长情况}{figure.caption.11}{}}
\newlabel{fig:dataset_size_growth}{{1.8b}{10}{训练数据集规模随时间增长情况}{figure.caption.11}{}}
\newlabel{sub@fig:dataset_size_growth}{{b}{10}{训练数据集规模随时间增长情况}{figure.caption.11}{}}
\newlabel{fig:compute_reqs_growth}{{1.8c}{10}{训练所需算力随时间变化情况}{figure.caption.11}{}}
\newlabel{sub@fig:compute_reqs_growth}{{c}{10}{训练所需算力随时间变化情况}{figure.caption.11}{}}
\newlabel{fig:accuracy_vs_size}{{1.8d}{10}{模型零样本准确率与模型规模关系}{figure.caption.11}{}}
\newlabel{sub@fig:accuracy_vs_size}{{d}{10}{模型零样本准确率与模型规模关系}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces 驱动现代大型语言模型发展的关键要素量化趋势}}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:llm_trends_overview}{{1.8}{10}{驱动现代大型语言模型发展的关键要素量化趋势}{figure.caption.11}{}}
\abx@aux@cite{0}{机器学习范式}
\abx@aux@segm{0}{0}{机器学习范式}
\abx@aux@cite{0}{rani2023self}
\abx@aux@segm{0}{0}{rani2023self}
\@writefile{toc}{\contentsline {chapter}{\numberline {第二章\hspace  {.3em}}现代人工智能的关键技术与突破}{11}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{chap:modern_ai_tech}{{二}{11}{现代人工智能的关键技术与突破}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}引言}{11}{section.2.1}\protected@file@percent }
\newlabel{sec:intro_chap2}{{2.1}{11}{引言}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}机器学习范式}{11}{section.2.2}\protected@file@percent }
\newlabel{sec:ml_paradigms}{{2.2}{11}{机器学习范式}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}监督学习}{11}{subsection.2.2.1}\protected@file@percent }
\newlabel{ssec:supervised_learning}{{2.2.1}{11}{监督学习}{subsection.2.2.1}{}}
\newlabel{sssec:digit_classification_case_study}{{2.2.1}{12}{案例研究：手写数字识别分类}{subsubsection*.12}{}}
\@writefile{toc}{\contentsline {paragraph}{1. 数据探索}{12}{paragraph*.13}\protected@file@percent }
\newlabel{fig:digit_distribution}{{2.1a}{13}{训练集中各数字的样本数量分布}{figure.caption.14}{}}
\newlabel{sub@fig:digit_distribution}{{a}{13}{训练集中各数字的样本数量分布}{figure.caption.14}{}}
\newlabel{fig:sample_digit}{{2.1b}{13}{一个手写数字“8”的样本图像}{figure.caption.14}{}}
\newlabel{sub@fig:sample_digit}{{b}{13}{一个手写数字“8”的样本图像}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 手写数字数据集的数据探索可视化}}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:digit_exploration}{{2.1}{13}{手写数字数据集的数据探索可视化}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{2. 模型评估与错误分析}{13}{paragraph*.15}\protected@file@percent }
\newlabel{fig:confusion_matrix}{{2.2a}{13}{模型在验证集上的混淆矩阵}{figure.caption.16}{}}
\newlabel{sub@fig:confusion_matrix}{{a}{13}{模型在验证集上的混淆矩阵}{figure.caption.16}{}}
\newlabel{fig:error_analysis}{{2.2b}{13}{模型错误分类的样本示例}{figure.caption.16}{}}
\newlabel{sub@fig:error_analysis}{{b}{13}{模型错误分类的样本示例}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces 分类模型的性能评估与错误分析}}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:classification_evaluation}{{2.2}{13}{分类模型的性能评估与错误分析}{figure.caption.16}{}}
\newlabel{sssec:lr_case_study}{{2.2.1}{14}{案例研究：线性回归的数学原理与实现}{subsubsection*.17}{}}
\@writefile{toc}{\contentsline {paragraph}{1. 矩阵化模型与正规方程}{14}{paragraph*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. 实例数据分析与可视化}{14}{paragraph*.19}\protected@file@percent }
\newlabel{fig:heatmap}{{2.3a}{14}{特征与目标值的相关性热力图}{figure.caption.20}{}}
\newlabel{sub@fig:heatmap}{{a}{14}{特征与目标值的相关性热力图}{figure.caption.20}{}}
\newlabel{fig:scatterplot}{{2.3b}{14}{原始数据分布散点图}{figure.caption.20}{}}
\newlabel{sub@fig:scatterplot}{{b}{14}{原始数据分布散点图}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces 线性回归案例的数据探索可视化}}{14}{figure.caption.20}\protected@file@percent }
\newlabel{fig:lr_data_exploration}{{2.3}{14}{线性回归案例的数据探索可视化}{figure.caption.20}{}}
\abx@aux@cite{0}{neuer2024unsupervised}
\abx@aux@segm{0}{0}{neuer2024unsupervised}
\abx@aux@cite{0}{shakya2023reinforcement}
\abx@aux@segm{0}{0}{shakya2023reinforcement}
\newlabel{fig:lr_concept}{{2.4a}{15}{线性回归概念示意图}{figure.caption.21}{}}
\newlabel{sub@fig:lr_concept}{{a}{15}{线性回归概念示意图}{figure.caption.21}{}}
\newlabel{fig:lr_results}{{2.4b}{15}{模型在测试集上的拟合效果}{figure.caption.21}{}}
\newlabel{sub@fig:lr_results}{{b}{15}{模型在测试集上的拟合效果}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces 线性回归模型概念与拟合结果}}{15}{figure.caption.21}\protected@file@percent }
\newlabel{fig:lr_fit_results}{{2.4}{15}{线性回归模型概念与拟合结果}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}无监督学习}{15}{subsection.2.2.2}\protected@file@percent }
\newlabel{ssec:unsupervised_learning}{{2.2.2}{15}{无监督学习}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}强化学习}{15}{subsection.2.2.3}\protected@file@percent }
\newlabel{ssec:reinforcement_learning}{{2.2.3}{15}{强化学习}{subsection.2.2.3}{}}
\abx@aux@cite{0}{hussain2022design}
\abx@aux@segm{0}{0}{hussain2022design}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}深度学习的崛起与应用}{16}{section.2.3}\protected@file@percent }
\newlabel{sec:dl_rise}{{2.3}{16}{深度学习的崛起与应用}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}卷积神经网络（CNN）与计算机视觉}{17}{subsection.2.3.1}\protected@file@percent }
\newlabel{ssec:cnn_cv}{{2.3.1}{17}{卷积神经网络（CNN）与计算机视觉}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}循环神经网络（RNN）与长短期记忆网络（LSTM）}{17}{subsection.2.3.2}\protected@file@percent }
\newlabel{ssec:rnn_lstm}{{2.3.2}{17}{循环神经网络（RNN）与长短期记忆网络（LSTM）}{subsection.2.3.2}{}}
\newlabel{sssec:lstm_case_study}{{2.3.2}{18}{案例研究：基于LSTM的文本分类（推文灾难识别）}{subsubsection*.22}{}}
\@writefile{toc}{\contentsline {paragraph}{1. LSTM核心数学表达式}{18}{paragraph*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. 探索性数据分析（EDA）}{19}{paragraph*.24}\protected@file@percent }
\newlabel{fig:char_dist}{{2.5a}{19}{推文中的字符数分布}{figure.caption.25}{}}
\newlabel{sub@fig:char_dist}{{a}{19}{推文中的字符数分布}{figure.caption.25}{}}
\newlabel{fig:word_dist}{{2.5b}{19}{推文中的词数分布}{figure.caption.25}{}}
\newlabel{sub@fig:word_dist}{{b}{19}{推文中的词数分布}{figure.caption.25}{}}
\newlabel{fig:avg_word_len}{{2.5c}{19}{推文中平均词长分布}{figure.caption.25}{}}
\newlabel{sub@fig:avg_word_len}{{c}{19}{推文中平均词长分布}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces 灾难性与非灾难性推文的基础文本统计对比}}{19}{figure.caption.25}\protected@file@percent }
\newlabel{fig:lstm_eda_basic}{{2.5}{19}{灾难性与非灾难性推文的基础文本统计对比}{figure.caption.25}{}}
\newlabel{fig:stopword_non_disaster}{{2.6a}{20}{非灾难性推文中的停用词}{figure.caption.26}{}}
\newlabel{sub@fig:stopword_non_disaster}{{a}{20}{非灾难性推文中的停用词}{figure.caption.26}{}}
\newlabel{fig:stopword_disaster}{{2.6b}{20}{灾难性推文中的停用词}{figure.caption.26}{}}
\newlabel{sub@fig:stopword_disaster}{{b}{20}{灾难性推文中的停用词}{figure.caption.26}{}}
\newlabel{fig:punct_disaster}{{2.6c}{20}{灾难性推文中的标点符号}{figure.caption.26}{}}
\newlabel{sub@fig:punct_disaster}{{c}{20}{灾难性推文中的标点符号}{figure.caption.26}{}}
\newlabel{fig:punct_non_disaster}{{2.6d}{20}{非灾难性推文中的标点符号}{figure.caption.26}{}}
\newlabel{sub@fig:punct_non_disaster}{{d}{20}{非灾难性推文中的标点符号}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces 灾难性与非灾难性推文中停用词与标点符号的对比分析}}{20}{figure.caption.26}\protected@file@percent }
\newlabel{fig:lstm_eda_stop_punct}{{2.6}{20}{灾难性与非灾难性推文中停用词与标点符号的对比分析}{figure.caption.26}{}}
\newlabel{fig:common_words}{{2.7a}{20}{常见词汇分析}{figure.caption.27}{}}
\newlabel{sub@fig:common_words}{{a}{20}{常见词汇分析}{figure.caption.27}{}}
\newlabel{fig:common_bigrams}{{2.7b}{20}{常见双词组合（Bigrams）分析}{figure.caption.27}{}}
\newlabel{sub@fig:common_bigrams}{{b}{20}{常见双词组合（Bigrams）分析}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces 推文中内容词汇的频率分析}}{20}{figure.caption.27}\protected@file@percent }
\newlabel{fig:lstm_eda_content}{{2.7}{20}{推文中内容词汇的频率分析}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Transformer架构与自注意力机制}{21}{subsection.2.3.3}\protected@file@percent }
\newlabel{ssec:transformer}{{2.3.3}{21}{Transformer架构与自注意力机制}{subsection.2.3.3}{}}
\newlabel{sssec:transformer_case_study}{{2.3.3}{21}{案例研究：Transformer的内部工作原理}{subsubsection*.28}{}}
\@writefile{toc}{\contentsline {paragraph}{1. 输入向量化与Q、K、V矩阵}{21}{paragraph*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces 从词嵌入向量X生成查询（Q）、键（K）、值（V）矩阵}}{22}{figure.caption.30}\protected@file@percent }
\newlabel{fig:qkv_creation}{{2.8}{22}{从词嵌入向量X生成查询（Q）、键（K）、值（V）矩阵}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {paragraph}{2. 缩放点积注意力（Scaled Dot-Product Attention）}{22}{paragraph*.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces 缩放点积注意力的计算流程}}{23}{figure.caption.32}\protected@file@percent }
\newlabel{fig:scaled_dot_product}{{2.9}{23}{缩放点积注意力的计算流程}{figure.caption.32}{}}
\@writefile{toc}{\contentsline {paragraph}{3. 多头注意力机制（Multi-Head Attention）}{23}{paragraph*.33}\protected@file@percent }
\newlabel{fig:multi_head_overview}{{2.10a}{23}{多头注意力机制概览}{figure.caption.34}{}}
\newlabel{sub@fig:multi_head_overview}{{a}{23}{多头注意力机制概览}{figure.caption.34}{}}
\newlabel{fig:multi_head_concat}{{2.10b}{23}{拼接多个注意力头的输出}{figure.caption.34}{}}
\newlabel{sub@fig:multi_head_concat}{{b}{23}{拼接多个注意力头的输出}{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces 多头注意力机制的分解与整合}}{23}{figure.caption.34}\protected@file@percent }
\newlabel{fig:multi_head_process}{{2.10}{23}{多头注意力机制的分解与整合}{figure.caption.34}{}}
\newlabel{fig:self_attention_it_1}{{2.11a}{24}{自注意力机制对“it”的指代分析（注意力头5）}{figure.caption.35}{}}
\newlabel{sub@fig:self_attention_it_1}{{a}{24}{自注意力机制对“it”的指代分析（注意力头5）}{figure.caption.35}{}}
\newlabel{fig:self_attention_it_2}{{2.11b}{24}{另一个注意力头对“it”的关注点}{figure.caption.35}{}}
\newlabel{sub@fig:self_attention_it_2}{{b}{24}{另一个注意力头对“it”的关注点}{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces 自注意力机制的可视化实例对比}}{24}{figure.caption.35}\protected@file@percent }
\newlabel{fig:self_attention_example}{{2.11}{24}{自注意力机制的可视化实例对比}{figure.caption.35}{}}
\@writefile{toc}{\contentsline {paragraph}{4. 整体架构：编码器与解码器}{24}{paragraph*.36}\protected@file@percent }
\newlabel{fig:encoder_block_1}{{2.12a}{24}{编码器（Encoder）层结构}{figure.caption.37}{}}
\newlabel{sub@fig:encoder_block_1}{{a}{24}{编码器（Encoder）层结构}{figure.caption.37}{}}
\newlabel{fig:encoder_block_2}{{2.12b}{24}{编码器中的Add \& Normalize细节}{figure.caption.37}{}}
\newlabel{sub@fig:encoder_block_2}{{b}{24}{编码器中的Add \& Normalize细节}{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Transformer编码器模块结构}}{24}{figure.caption.37}\protected@file@percent }
\newlabel{fig:encoder_block}{{2.12}{24}{Transformer编码器模块结构}{figure.caption.37}{}}
\abx@aux@cite{0}{15}
\abx@aux@segm{0}{0}{15}
\newlabel{fig:transformer_architecture}{{2.13a}{25}{完整的Transformer模型架构}{figure.caption.38}{}}
\newlabel{sub@fig:transformer_architecture}{{a}{25}{完整的Transformer模型架构}{figure.caption.38}{}}
\newlabel{fig:final_output_layer}{{2.13b}{25}{最终的线性和Softmax输出层}{figure.caption.38}{}}
\newlabel{sub@fig:final_output_layer}{{b}{25}{最终的线性和Softmax输出层}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Transformer整体架构与输出层}}{25}{figure.caption.38}\protected@file@percent }
\newlabel{fig:transformer_full_view}{{2.13}{25}{Transformer整体架构与输出层}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}生成式人工智能（Generative AI）}{25}{section.2.4}\protected@file@percent }
\newlabel{sec:generative_ai}{{2.4}{25}{生成式人工智能（Generative AI）}{section.2.4}{}}
\newlabel{sssec:gan_case_study}{{2.4}{25}{案例研究：GAN的博弈过程与训练细节}{subsubsection*.39}{}}
\abx@aux@cite{0}{15}
\abx@aux@segm{0}{0}{15}
\abx@aux@cite{0}{15}
\abx@aux@segm{0}{0}{15}
\abx@aux@cite{0}{15}
\abx@aux@segm{0}{0}{15}
\newlabel{fig:gan_discriminator_model}{{2.14a}{26}{判别模型（Discriminative Model）示意图}{figure.caption.40}{}}
\newlabel{sub@fig:gan_discriminator_model}{{a}{26}{判别模型（Discriminative Model）示意图}{figure.caption.40}{}}
\newlabel{fig:gan_generative_model}{{2.14b}{26}{生成模型（Generative Model）示意图}{figure.caption.40}{}}
\newlabel{sub@fig:gan_generative_model}{{b}{26}{生成模型（Generative Model）示意图}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces GAN的两个核心组件：判别器与生成器}}{26}{figure.caption.40}\protected@file@percent }
\newlabel{fig:gan_components}{{2.14}{26}{GAN的两个核心组件：判别器与生成器}{figure.caption.40}{}}
\@writefile{toc}{\contentsline {paragraph}{1. 训练过程的数学解析}{26}{paragraph*.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces GAN的整体训练循环示意图,展示了从真实样本（Real Samples）和生成样本（Generated Samples）到判别器和损失函数的完整流程}}{26}{figure.caption.42}\protected@file@percent }
\newlabel{fig:gan_full_training_loop}{{2.15}{26}{GAN的整体训练循环示意图,展示了从真实样本（Real Samples）和生成样本（Generated Samples）到判别器和损失函数的完整流程}{figure.caption.42}{}}
\abx@aux@cite{0}{89}
\abx@aux@segm{0}{0}{89}
\abx@aux@cite{0}{90}
\abx@aux@segm{0}{0}{90}
\newlabel{fig:gan_train_discriminator}{{2.16a}{27}{训练判别器D的阶段：固定G,优化D以区分真伪样本。真实样本x的标签为1,生成样本G(z)的标签为0。}{figure.caption.43}{}}
\newlabel{sub@fig:gan_train_discriminator}{{a}{27}{训练判别器D的阶段：固定G,优化D以区分真伪样本。真实样本x的标签为1,生成样本G(z)的标签为0。}{figure.caption.43}{}}
\newlabel{fig:gan_train_generator}{{2.16b}{27}{训练生成器G的阶段：固定D,优化G以生成能让D判断为“真”（标签1）的样本。}{figure.caption.43}{}}
\newlabel{sub@fig:gan_train_generator}{{b}{27}{训练生成器G的阶段：固定D,优化G以生成能让D判断为“真”（标签1）的样本。}{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces GAN训练的两个交替阶段对比}}{27}{figure.caption.43}\protected@file@percent }
\newlabel{fig:gan_training_phases}{{2.16}{27}{GAN训练的两个交替阶段对比}{figure.caption.43}{}}
\@writefile{toc}{\contentsline {paragraph}{2. 收敛与理论最优解}{27}{paragraph*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. GAN的架构与应用实例}{27}{paragraph*.45}\protected@file@percent }
\abx@aux@cite{0}{croitoru2023diffusion}
\abx@aux@segm{0}{0}{croitoru2023diffusion}
\newlabel{fig:dcgan_generator_arch}{{2.17a}{28}{一个典型的DCGAN生成器网络结构}{figure.caption.46}{}}
\newlabel{sub@fig:dcgan_generator_arch}{{a}{28}{一个典型的DCGAN生成器网络结构}{figure.caption.46}{}}
\newlabel{fig:gan_manifold_learning}{{2.17b}{28}{GAN学习数据流形的可视化过程}{figure.caption.46}{}}
\newlabel{sub@fig:gan_manifold_learning}{{b}{28}{GAN学习数据流形的可视化过程}{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces DCGAN架构示例与GAN的流形学习能力}}{28}{figure.caption.46}\protected@file@percent }
\newlabel{fig:gan_arch_and_manifold}{{2.17}{28}{DCGAN架构示例与GAN的流形学习能力}{figure.caption.46}{}}
\newlabel{sssec:diffusion_case_study}{{2.4}{28}{案例研究：扩散模型的数学原理与实现}{subsubsection*.47}{}}
\@writefile{toc}{\contentsline {paragraph}{1. 前向过程（Forward Process / Diffusion Process）}{28}{paragraph*.48}\protected@file@percent }
\abx@aux@cite{0}{315}
\abx@aux@segm{0}{0}{315}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces 扩散模型的前向过程：从清晰图像（$x_0$）逐步添加噪声,直至变为纯噪声图像（$x_T$）。}}{29}{figure.caption.49}\protected@file@percent }
\newlabel{fig:diffusion_forward_process}{{2.18}{29}{扩散模型的前向过程：从清晰图像（$x_0$）逐步添加噪声,直至变为纯噪声图像（$x_T$）。}{figure.caption.49}{}}
\@writefile{toc}{\contentsline {paragraph}{2. 反向过程（Reverse Process / Denoising Process）}{29}{paragraph*.50}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces 扩散模型的反向（去噪）过程：从随机噪声（$x_T$）开始,由神经网络引导,逐步恢复出清晰图像（$x_0$）。}}{29}{figure.caption.51}\protected@file@percent }
\newlabel{fig:diffusion_reverse_process}{{2.19}{29}{扩散模型的反向（去噪）过程：从随机噪声（$x_T$）开始,由神经网络引导,逐步恢复出清晰图像（$x_0$）。}{figure.caption.51}{}}
\@writefile{toc}{\contentsline {paragraph}{3. 训练目标与损失函数}{30}{paragraph*.52}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces 扩散模型的训练目标：神经网络 $\epsilon _\theta $ 学习预测在时间步t添加到原始图像$x_0$上的噪声。}}{30}{figure.caption.53}\protected@file@percent }
\newlabel{fig:diffusion_training_objective}{{2.20}{30}{扩散模型的训练目标：神经网络 $\epsilon _\theta $ 学习预测在时间步t添加到原始图像$x_0$上的噪声。}{figure.caption.53}{}}
\@writefile{toc}{\contentsline {paragraph}{4. 架构与应用实例}{30}{paragraph*.54}\protected@file@percent }
\newlabel{fig:glide_example}{{2.21a}{31}{GLIDE}{figure.caption.55}{}}
\newlabel{sub@fig:glide_example}{{a}{31}{GLIDE}{figure.caption.55}{}}
\newlabel{fig:dalle2_example}{{2.21b}{31}{DALL-E 2}{figure.caption.55}{}}
\newlabel{sub@fig:dalle2_example}{{b}{31}{DALL-E 2}{figure.caption.55}{}}
\newlabel{fig:imagen_example}{{2.21c}{31}{Imagen}{figure.caption.55}{}}
\newlabel{sub@fig:imagen_example}{{c}{31}{Imagen}{figure.caption.55}{}}
\newlabel{fig:stable_diffusion_example}{{2.21d}{31}{Stable Diffusion}{figure.caption.55}{}}
\newlabel{sub@fig:stable_diffusion_example}{{d}{31}{Stable Diffusion}{figure.caption.55}{}}
\newlabel{fig:sdxl_turbo_example}{{2.21e}{31}{SDXL Turbo}{figure.caption.55}{}}
\newlabel{sub@fig:sdxl_turbo_example}{{e}{31}{SDXL Turbo}{figure.caption.55}{}}
\newlabel{fig:sd3_example}{{2.21f}{31}{Stable Diffusion 3}{figure.caption.55}{}}
\newlabel{sub@fig:sd3_example}{{f}{31}{Stable Diffusion 3}{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces 不同文本到图像扩散模型生成的图像示例}}{31}{figure.caption.55}\protected@file@percent }
\newlabel{fig:diffusion_model_examples}{{2.21}{31}{不同文本到图像扩散模型生成的图像示例}{figure.caption.55}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}大型语言模型（LLMs）的兴起}{32}{section.2.5}\protected@file@percent }
\newlabel{sec:llms}{{2.5}{32}{大型语言模型（LLMs）的兴起}{section.2.5}{}}
\newlabel{sssec:llm_case_study}{{2.5}{32}{案例研究：大型语言模型的规模效应与趋势}{subsubsection*.56}{}}
\@writefile{toc}{\contentsline {paragraph}{1. 缩放法则的数学表达}{32}{paragraph*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. 发展趋势的可视化分析}{33}{paragraph*.58}\protected@file@percent }
\newlabel{fig:llm_compute_summary}{{2.22a}{33}{AI领域训练计算量的总体趋势}{figure.caption.59}{}}
\newlabel{sub@fig:llm_compute_summary}{{a}{33}{AI领域训练计算量的总体趋势}{figure.caption.59}{}}
\newlabel{fig:llm_compute_by_type}{{2.22b}{33}{不同类型大型AI模型的计算量增长}{figure.caption.59}{}}
\newlabel{sub@fig:llm_compute_by_type}{{b}{33}{不同类型大型AI模型的计算量增长}{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces AI模型训练计算量的指数级增长趋势}}{33}{figure.caption.59}\protected@file@percent }
\newlabel{fig:llm_compute_trends}{{2.22}{33}{AI模型训练计算量的指数级增长趋势}{figure.caption.59}{}}
\newlabel{fig:llm_training_cost}{{2.23a}{34}{部分知名AI模型的预估训练成本}{figure.caption.60}{}}
\newlabel{sub@fig:llm_training_cost}{{a}{34}{部分知名AI模型的预估训练成本}{figure.caption.60}{}}
\newlabel{fig:llm_reason_class}{{2.23b}{34}{人类判断不同AI为“人工智能”的原因分布}{figure.caption.60}{}}
\newlabel{sub@fig:llm_reason_class}{{b}{34}{人类判断不同AI为“人工智能”的原因分布}{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces 大型AI模型的训练成本与人类感知分析}}{34}{figure.caption.60}\protected@file@percent }
\newlabel{fig:llm_cost_perception}{{2.23}{34}{大型AI模型的训练成本与人类感知分析}{figure.caption.60}{}}
\@writefile{toc}{\contentsline {paragraph}{3. 模型性能与置信度校准}{34}{paragraph*.61}\protected@file@percent }
\newlabel{fig:llm_accuracy_confidence}{{2.24a}{35}{不同AI的准确率与置信度关系}{figure.caption.62}{}}
\newlabel{sub@fig:llm_accuracy_confidence}{{a}{35}{不同AI的准确率与置信度关系}{figure.caption.62}{}}
\newlabel{fig:llm_winrate_confidence}{{2.24b}{35}{不同AI在对比测试中的胜率与置信度}{figure.caption.62}{}}
\newlabel{sub@fig:llm_winrate_confidence}{{b}{35}{不同AI在对比测试中的胜率与置信度}{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces 大型语言模型的置信度校准与性能评估}}{35}{figure.caption.62}\protected@file@percent }
\newlabel{fig:llm_confidence_calibration}{{2.24}{35}{大型语言模型的置信度校准与性能评估}{figure.caption.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}其他新兴技术}{35}{section.2.6}\protected@file@percent }
\newlabel{sec:emerging_tech}{{2.6}{35}{其他新兴技术}{section.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}总结}{36}{section.2.7}\protected@file@percent }
\newlabel{sec:conclusion_chap2}{{2.7}{36}{总结}{section.2.7}{}}
\@writefile{toc}{\contentsline {chapter}{参考文献}{37}{chapter*.63}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{C8E6C11DE5AE67D90227020A92F74B10}
\abx@aux@defaultrefcontext{0}{casal2023ai}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhai2021review}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mahesh2020machine}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lecun2015deep}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{glielmo2021unsupervised}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{matsuo2022deep}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ahmed2023deep}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{jung2023concerning}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{maurer2021cognitive}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{shehadeh2024expert}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{xu2022separable}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{机器学习范式}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rani2023self}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{neuer2024unsupervised}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{shakya2023reinforcement}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hussain2022design}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{croitoru2023diffusion}{none/global//global/global/global}
\gdef \@abspage@last{43}
